# -----------------------------------------------------------------------------
net:
  depth:
    enc_name: 'convnext_tiny'
    pretrained: True
    dec_name: 'monodepth'
    out_scales: [0, 1, 2, 3]
    use_virtual_stereo: False
    mask_name: ~
    num_ch_mask: ~
    use_stereo_blend: False

  pose:
    enc_name: 'resnet18'
    pretrained: True
# -----------------------------------------------------------------------------
loss:
  img_recon:
    weight: 1
    use_min: False
    use_automask: False

  disp_smooth:
    weight: 0.001
    use_edges: True
    use_laplacian: False
    use_blur: False
# -----------------------------------------------------------------------------
dataset:
  kitti_lmdb:
    split: 'eigen_benchmark'
    datum: 'image support depth K'
    shape: [ 192, 640 ]
    supp_idxs: [ -1, 1 ]
    max_len: 10000
    randomize: True

    train: { mode: 'train', use_aug: True }
    val: { mode: 'val', use_aug: False }

  mannequin_lmdb:
    datum: 'image support K'
    shape: [ 384, 640 ]
    supp_idxs: [ -1, 1 ]
    max_len: 10000
    randomize: True

    train: { mode: 'train', use_aug: True }
    val: { mode: 'val', use_aug: False }

  slow_tv_lmdb:
    split: 'all'
    datum: 'image support K'
    shape: [ 384, 640 ]
    supp_idxs: [ -1, 1 ]
    max_len: 20000
    randomize: True

    train: { mode: 'train', use_aug: True }
    val: { mode: 'val', use_aug: False }
# -----------------------------------------------------------------------------
loader:
  batch_size: 4
  drop_last: True

  train: { shuffle: True, num_workers: 6 }
  val: { shuffle: False, num_workers: 1 }
# -----------------------------------------------------------------------------
optimizer:
  type: 'adamw'
  lr: 0.0001
# -----------------------------------------------------------------------------
scheduler:
  steplr:
    step_size: 20
    gamma: 0.1

  linear:
    start_factor: 0.1
    total_iters: 2
# -----------------------------------------------------------------------------
trainer:
  max_epochs: 30
  resume_training: True
  load_ckpt: ~
  log_every_n_steps: 100
  monitor: 'loss'

  min_depth: 0.1
  max_depth: 100

  benchmark: True
  gradient_clip_val: ~
  precision: 32  # 16 is causing NaNs...
  accumulate_grad_batches: 1

  always_fwd_pose: False

  swa: ~
  early_stopping: ~
# -----------------------------------------------------------------------------